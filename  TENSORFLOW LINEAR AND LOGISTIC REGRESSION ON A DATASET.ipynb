{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sex  Length  Diameter  Height  Whole Weigth  Shucked weight  Viscera weight  \\\n",
      "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell weight  Rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7   \n",
      "\n",
      "SHAPE of data set (4177, 9) \n",
      "\n",
      "            Length     Diameter       Height  Whole Weigth  Shucked weight  \\\n",
      "count  4177.000000  4177.000000  4177.000000   4177.000000     4177.000000   \n",
      "mean      0.523992     0.407881     0.139516      0.828742        0.359367   \n",
      "std       0.120093     0.099240     0.041827      0.490389        0.221963   \n",
      "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
      "25%       0.450000     0.350000     0.115000      0.441500        0.186000   \n",
      "50%       0.545000     0.425000     0.140000      0.799500        0.336000   \n",
      "75%       0.615000     0.480000     0.165000      1.153000        0.502000   \n",
      "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
      "\n",
      "       Viscera weight  Shell weight        Rings  \n",
      "count     4177.000000   4177.000000  4177.000000  \n",
      "mean         0.180594      0.238831     9.933684  \n",
      "std          0.109614      0.139203     3.224169  \n",
      "min          0.000500      0.001500     1.000000  \n",
      "25%          0.093500      0.130000     8.000000  \n",
      "50%          0.171000      0.234000     9.000000  \n",
      "75%          0.253000      0.329000    11.000000  \n",
      "max          0.760000      1.005000    29.000000   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "#COMPARING THE LOSS DURING TRAINING USING LINEAR AND LOGISTICS REGRESSION\n",
    "\n",
    "df = pd.read_csv(\"abalone.csv\")\n",
    "#to know about the dataset\n",
    "\n",
    "print(df.head(),\"\\n\") \n",
    "\n",
    "#TO KNOW THE SHAPE OF THE DATASET\n",
    "print (\"SHAPE of data set\",df.shape,\"\\n\")\n",
    "\n",
    "#to know the mean , stds...\n",
    "print(df.describe(),\"\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sex  Length  Diameter  Height  Whole Weigth  Shucked weight  Viscera weight  \\\n",
      "0   0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   0   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   1   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   0   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   1   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell weight  Rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#convert sex column to zeros and ones \n",
    "df.Sex[df.Sex == 'M'] = 0\n",
    "df.Sex[df.Sex == 'F'] = 1\n",
    "df.Sex[df.Sex == 'I'] = 0.5\n",
    "\n",
    "\n",
    "print(df.head(5)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 loss= 11.996692\n",
      "Epoch: 0020 loss= 11.8678875\n",
      "Epoch: 0030 loss= 11.648458\n",
      "Epoch: 0040 loss= 11.356975\n",
      "Epoch: 0050 loss= 11.088488\n",
      "Epoch: 0060 loss= 10.892545\n",
      "Epoch: 0070 loss= 10.759552\n",
      "Epoch: 0080 loss= 10.6687155\n",
      "Epoch: 0090 loss= 10.604666\n",
      "Epoch: 0100 loss= 10.557848\n",
      "Epoch: 0110 loss= 10.522474\n",
      "Epoch: 0120 loss= 10.4949665\n",
      "Epoch: 0130 loss= 10.473045\n",
      "Epoch: 0140 loss= 10.455211\n",
      "Epoch: 0150 loss= 10.440442\n",
      "Epoch: 0160 loss= 10.428025\n",
      "Epoch: 0170 loss= 10.417445\n",
      "Epoch: 0180 loss= 10.408332\n",
      "Epoch: 0190 loss= 10.400399\n",
      "Epoch: 0200 loss= 10.393437\n",
      "\n",
      " the initial loss is high \n",
      " but it still reduces on training\n",
      "Performing a logistic regression on this same dataset provides a lower loss\n"
     ]
    }
   ],
   "source": [
    "#COMPUTATIONAL GRAPH\n",
    "\n",
    "\n",
    "\n",
    "#INPUT DATA X\n",
    "x_data = df[[\"Rings\",\"Sex\",\"Diameter\",\"Length\",\"Height\",\"Whole Weigth\",\"Shucked weight\",\"Viscera weight\",\"Shell weight\"]]\n",
    "\n",
    "#LABELS OR COLUMN FEATURES Y\n",
    "\n",
    "y_data= df[[\"Sex\",\"Diameter\",\"Length\",\"Height\",\"Whole Weigth\",\"Shucked weight\",\"Viscera weight\",\"Shell weight\",\"Rings\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#INPUT X DATA\n",
    "X = tf.placeholder(tf.float32, shape = (4177,9))\n",
    "\n",
    "#INPUT Y DATA COLUMN FEATURES OR LABELS\n",
    "Y = tf.placeholder(tf.float32, shape = (None,9))\n",
    "\n",
    "#m= tf.Variable([[0,0,0,0,0,0,0,0,0]], dtype=tf.float32, name='m')\n",
    "\n",
    "   #OR\n",
    "m= tf.Variable(tf.zeros([9,9]), dtype=tf.float32, name='m')\n",
    "\n",
    "        #INITIALISE BIAS WITH ZERO\n",
    "c = tf.Variable(0, dtype=tf.float32, name='c')\n",
    "\n",
    "YPred=tf.nn.softmax(tf.matmul(X, m) + c)\n",
    "\n",
    "        #USE LINEAER REGRESSION lOSS FORMULAR tf.squared_difference ON YPRED\n",
    "\n",
    "loss = tf.reduce_mean(tf.squared_difference(YPred, Y))\n",
    "\n",
    "        #USE GRADIENT DESCCENT OPTIMIZER\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate= 0.001)\n",
    "\n",
    "        #MINIMISE LOSS\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "\n",
    "previous_m = np.inf\n",
    "previous_c = np.inf\n",
    "\n",
    "\n",
    "numofiterations=200\n",
    "\n",
    "\n",
    "display_step = 10\n",
    "\n",
    "wb=[]\n",
    "\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for k in range(numofiterations):\n",
    "    \n",
    "        _, _m, _c, _l = sess.run([train, m, c, loss], feed_dict = {X:x_data, Y:y_data})\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "        if (k+1) % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (k+1), \"loss=\", _l)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        if (np.all(previous_m - _m) <=learning_rate ) or (np.all(previous_c - _c) <= learning_rate):\n",
    "\n",
    "           \n",
    "            break\n",
    "\n",
    "print (\"\\n the initial loss:11.996692 is high  \\n but it still reduces on training\")\n",
    "print (\"Performing a logistic regression on this same dataset provides a lower loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 loss= 0.5714785\n",
      "Epoch: 0020 loss= 0.5496836\n",
      "Epoch: 0030 loss= 0.5206854\n",
      "Epoch: 0040 loss= 0.48170382\n",
      "Epoch: 0050 loss= 0.42996946\n",
      "Epoch: 0060 loss= 0.36467037\n",
      "Epoch: 0070 loss= 0.28924093\n",
      "Epoch: 0080 loss= 0.21089435\n",
      "Epoch: 0090 loss= 0.13693409\n",
      "Epoch: 0100 loss= 0.071775496\n",
      "Epoch: 0110 loss= 0.016733844\n",
      "Epoch: 0120 loss= -0.028783156\n",
      "Epoch: 0130 loss= -0.06614384\n",
      "Epoch: 0140 loss= -0.0968375\n",
      "Epoch: 0150 loss= -0.12219555\n",
      "Epoch: 0160 loss= -0.14331359\n",
      "Epoch: 0170 loss= -0.16105935\n",
      "Epoch: 0180 loss= -0.17610918\n",
      "Epoch: 0190 loss= -0.18898782\n",
      "Epoch: 0200 loss= -0.20010304\n",
      "\n",
      " the logistic regression initial loss:  8.074295 ,is lower than linear regression initial loss which was :11.996692 \n",
      " Because of the Logistic regression SIGMOID FUNCTION\n",
      "And it also reduces with a lower loss\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#LOGISTIC REGRESSION ON THE ABOVE DATASET USING THE SAME PARAMETER\n",
    "\n",
    "\n",
    "\n",
    "#DEFINE SIGMOID FOR LOGISTIC REGRESSION\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+tf.math.exp(-x))#FORMULAR FOR SIGMOID\n",
    "\n",
    "\n",
    "#OR USE tf.nn.sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "#INPUT DATA X\n",
    "x_data = df[[\"Rings\",\"Sex\",\"Diameter\",\"Length\",\"Height\",\"Whole Weigth\",\"Shucked weight\",\"Viscera weight\",\"Shell weight\"]]\n",
    "\n",
    "#LABELS OR COLUMN FEATURES Y\n",
    "\n",
    "y_data= df[[\"Sex\",\"Diameter\",\"Length\",\"Height\",\"Whole Weigth\",\"Shucked weight\",\"Viscera weight\",\"Shell weight\",\"Rings\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#COMPUTATIONAL GRAPH\n",
    "\n",
    "#INPUT X DATA\n",
    "X = tf.placeholder(tf.float32, shape = (4177,9))\n",
    "\n",
    "#INPUT Y DATA COLUMN FEATURES OR LABELS\n",
    "Y = tf.placeholder(tf.float32, shape = (None,9))\n",
    "\n",
    "\n",
    "      #INITIALISE WEIGHT WITH ZERO\n",
    "\n",
    "#m= tf.Variable([[0,0,0,0,0,0,0,0,0]], dtype=tf.float32, name='m')\n",
    "    #OR\n",
    "\n",
    "m= tf.Variable(tf.zeros([9,9]), dtype=tf.float32, name='m')\n",
    "\n",
    "        #INITIALISE BIAS WITH ZERO\n",
    "c = tf.Variable(0, dtype=tf.float32, name='c')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "YPred=tf.nn.softmax(tf.matmul(X, m) + c)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#USE LOGISTIC REGRESSION SIGMOID FUNCTION ON YPRED\n",
    "\n",
    "# Minimize error using tensorflow sigmoid cross entropy\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=YPred)\n",
    "      \n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "# Gradient Descent TO MIMIMISE LOSS\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate= 0.001).minimize(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "\n",
    "previous_m = np.inf\n",
    "previous_c = np.inf\n",
    "\n",
    "\n",
    "display_step = 10\n",
    "\n",
    "numofiterations=200\n",
    "\n",
    "\n",
    "losses=[]\n",
    "wb=[]\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for k in range(numofiterations):\n",
    "        avg_cost = 0.\n",
    "        _, _m, _c, _l = sess.run([train, m, c, loss], feed_dict = {X:x_data, Y:y_data})\n",
    "\n",
    "         \n",
    "       \n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "        if (k+1) % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (k+1), \"loss=\", _l)\n",
    "        \n",
    "\n",
    "        if (np.all(previous_m - _m) <= learning_rate) or (np.all(previous_c - _c) <= learning_rate):\n",
    "\n",
    "            \n",
    "            break\n",
    "        \n",
    "print (\"\\n the logistic regression initial loss:  8.074295 ,is lower than linear regression initial loss which was :11.996692 \\n Because of the Logistic regression SIGMOID FUNCTION\")\n",
    "print (\"And it also reduces with a lower loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
